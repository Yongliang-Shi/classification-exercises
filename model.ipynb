{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Environment\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire, prepare\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_metrics(alg, X, y):\n",
    "    alg.fit(X, y)\n",
    "    score = alg.score(X, y)\n",
    "    y_pred = alg.predict(X)\n",
    "    report = classification_report(y, y_pred, output_dict=True)\n",
    "    report = pd.DataFrame(report).drop(columns=['accuracy', 'macro avg', 'weighted avg']).T\n",
    "    report['FPR/FNR'] = 1 - report.recall\n",
    "    report['accuracy'] = score\n",
    "    report.rename(columns={'recall':'TNR/TPR'}, inplace=True)\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Througout this exercise, be sure you are training, evaluation, and comparing models on the train and validate dataset. The test dataset should be only used for your final model. \n",
    "\n",
    "### For all of the models you create, choose a threshold that optimizes for accuracy. \n",
    "\n",
    "### Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeways**:\n",
    "1. Build logistic regression models for titanic dataset.\n",
    "2. Several models need to be build. \n",
    "3. Accuray is the evaluation metrics. \n",
    "4. Target varibale: the survivied (categorical)\n",
    "5. The positive case is predicting the survivied\n",
    "    - TP: predicting survived actually survivied\n",
    "    - FP: predicting survived actually being a victim\n",
    "    - TN: predicting being a victim acturally was a victim\n",
    "    - FN: predicting being a victim acturally survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create another model that includes age in addition to fare and pclass. Does this model perform better than your previous one? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire titanic data.\n",
    "\n",
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare titanic dataset\n",
    "\n",
    "train, validate, test = prepare.prep_titanic(titanic)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check if there is any missing values\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute the baseline accuracy\n",
    "\n",
    "train.survived.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BL_Model: X = ['fare', 'pclass'], y = 'survived'\n",
    "1. fare: continuous\n",
    "2. pclass: categotical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare and pclass are the X in model1.\n",
    "\n",
    "X_train_model1 = train[['fare', 'pclass']]\n",
    "y_train_model1 = train[['survived']]\n",
    "\n",
    "X_train_model1.shape, y_train_model1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the logistic regression object\n",
    "\n",
    "logit1 = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "logit1.fit(X_train_model1, y_train_model1)\n",
    "\n",
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit1.coef_)\n",
    "print('Intercept: \\n', logit1.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model1 = logit1.predict(X_train_model1)\n",
    "y_pred_model1\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model1 = logit1.predict_proba(X_train_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evalute model on train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy\n",
    "\n",
    "print(logit1.score(X_train_model1, y_train_model1))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_train_model1, y_pred_model1))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_train_model1, y_pred_model1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: X = ['fare', 'pclass', 'age'], y = 'survived'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare, pclass, age are the X in model2.\n",
    "\n",
    "X_train_model2 = train[['fare', 'pclass', 'age']]\n",
    "y_train_model2 = train[['survived']]\n",
    "\n",
    "X_train_model2.shape, y_train_model2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create, Fit & Predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the logistic regression object\n",
    "\n",
    "logit2 = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "logit2.fit(X_train_model2, y_train_model2)\n",
    "\n",
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit2.coef_)\n",
    "print('Intercept: \\n', logit2.intercept_)\n",
    "\n",
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model2 = logit2.predict(X_train_model2)\n",
    "y_pred_model2\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model2 = logit2.predict_proba(X_train_model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evalute model on train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy\n",
    "\n",
    "print('Accuracy: {: .2f}'.format(logit2.score(X_train_model2, y_train_model2)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_train_model2, y_pred_model2))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_train_model2, y_pred_model2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sex_dummy = pd.get_dummies(train.sex)\n",
    "train = pd.concat([train, sex_dummy], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 3: X = ['fare', 'pclass', 'age', 'male'], y = ['survivied']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare, pclass, age, and male are the X in model2.\n",
    "\n",
    "X_train_model3 = train[['fare', 'pclass', 'age', 'male']]\n",
    "y_train_model3 = train[['survived']]\n",
    "\n",
    "X_train_model3.shape, y_train_model3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the logistic regression object\n",
    "\n",
    "logit3 = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "logit3.fit(X_train_model3, y_train_model3)\n",
    "\n",
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit3.coef_)\n",
    "print('Intercept: \\n', logit3.intercept_)\n",
    "\n",
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model3 = logit3.predict(X_train_model3)\n",
    "y_pred_model3\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model3 = logit3.predict_proba(X_train_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy\n",
    "\n",
    "print('Accuracy: {: .2f}'.format(logit3.score(X_train_model3, y_train_model3)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print('Confusion matrix: ', confusion_matrix(y_train_model3, y_pred_model3))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_train_model3, y_pred_model3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. Previous model only contains fare and pclass as the X. \n",
    "2. No missing values in the train dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Try out other combinations of features and models.\n",
    "* Model 4: X = ['pcalss', 'male'], y = 'survived'\n",
    "* Create, fit and predict\n",
    "* Accuracy, Confustion matrix, and Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pclass and male are the X in model 4.\n",
    "\n",
    "X_train_model4 = train[['pclass', 'male']]\n",
    "y_train_model4 = train[['survived']]\n",
    "\n",
    "# Create the logistic regression object\n",
    "\n",
    "logit4 = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "logit4.fit(X_train_model4, y_train_model4)\n",
    "\n",
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit4.coef_)\n",
    "print('Intercept: \\n', logit4.intercept_)\n",
    "\n",
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model4 = logit4.predict(X_train_model4)\n",
    "y_pred_model4\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model4 = logit4.predict_proba(X_train_model4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy\n",
    "\n",
    "print('Accuracy: {: .2f}'.format(logit4.score(X_train_model4, y_train_model4)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_train_model4, y_pred_model4))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_train_model4, y_pred_model4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use best 3 models to predict and evaluate your validate sample\n",
    "* Best 3: model 2, 3, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validate dataset\n",
    "\n",
    "validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummy = pd.get_dummies(validate.sex)\n",
    "validate = pd.concat([validate, sex_dummy], axis=1)\n",
    "validate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validate dataset for Model 2\n",
    "\n",
    "X_validate_model2 = validate[['fare', 'pclass', 'age']]\n",
    "y_validate_model2 = validate[['survived']]\n",
    "\n",
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model2 = logit2.predict(X_validate_model2)\n",
    "y_pred_model2\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model2 = logit2.predict_proba(X_validate_model2)\n",
    "\n",
    "# Compute the accuracy\n",
    "\n",
    "print('Accuracy: {: .2f}'.format(logit2.score(X_validate_model2, y_validate_model2)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_validate_model2, y_pred_model2))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_validate_model2, y_pred_model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validate dataset for Model 3\n",
    "\n",
    "X_validate_model3 = validate[['fare', 'pclass', 'age', 'male']]\n",
    "y_validate_model3 = validate[['survived']]\n",
    "\n",
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model3 = logit3.predict(X_validate_model3)\n",
    "y_pred_model3\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model3 = logit3.predict_proba(X_validate_model3)\n",
    "\n",
    "# Compute the accuracy\n",
    "\n",
    "print('Accuracy: {: .2f}'.format(logit3.score(X_validate_model3, y_validate_model3)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_validate_model3, y_pred_model3))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_validate_model3, y_pred_model3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validate dataset for Model 4\n",
    "\n",
    "X_validate_model4 = validate[['pclass', 'male']]\n",
    "y_validate_model4 = validate[['survived']]\n",
    "\n",
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model4 = logit4.predict(X_validate_model4)\n",
    "y_pred_model4\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model4 = logit4.predict_proba(X_validate_model4)\n",
    "\n",
    "# Compute the accuracy\n",
    "\n",
    "print('Accuracy: {: .2f}'.format(logit4.score(X_validate_model4, y_validate_model4)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_validate_model4, y_pred_model4))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_validate_model4, y_pred_model4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?\n",
    "* Best model from the validation: Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_dummy = pd.get_dummies(test.sex)\n",
    "test = pd.concat([test, sex_dummy], axis=1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test dataset for Model 3\n",
    "\n",
    "X_test_model3 = test[['fare', 'pclass', 'age', 'male']]\n",
    "y_test_model3 = test[['survived']]\n",
    "\n",
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model3 = logit3.predict(X_test_model3)\n",
    "y_pred_model3\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model3 = logit3.predict_proba(X_test_model3)\n",
    "\n",
    "# Compute the accuracy\n",
    "\n",
    "print('Accuracy: {: .2f}'.format(logit3.score(X_test_model3, y_test_model3)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print(confusion_matrix(y_test_model3, y_pred_model3))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_test_model3, y_pred_model3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**: The accuracy from test dataset(0.80) is a little better than the validate(0.78) and train(0.79)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 1. How do different strategies for handling the missing values in the age column affect model performance? \n",
    "\n",
    "**Notes**\n",
    "1. In the current titanic dataset, the stragegy for handling the missing values in the age column is SimpleImpute = 'most_frequent')\n",
    "2. There are four strategies in the SimpleImpute:\n",
    "    - mean\n",
    "    - median\n",
    "    - most_frequent\n",
    "    - constant\n",
    "3. The best model for now is Model 3\n",
    "\n",
    "**My Plan**\n",
    "\n",
    "1. I will use a different strategy in SimpleImpute and then compare the performance for model 3. \n",
    "2. Which stragegy I am gonna use? mean or median. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_titanic = acquire.get_titanic_data()\n",
    "raw_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age columns has 177 null values\n",
    "\n",
    "null_age = raw_titanic.age.isnull().sum()\n",
    "null_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The percentage of null values in age column\n",
    "\n",
    "null_age/raw_titanic.age.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most frequent age\n",
    "\n",
    "# raw_titanic.age.value_counts().head(1)\n",
    "raw_titanic.age.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_titanic.age.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_titanic.age.agg(['mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Who are missing the age values?\n",
    "\n",
    "mask = raw_titanic.age.isnull()\n",
    "raw_titanic[mask].alone.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_titanic_mean(raw_titanic)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of age distrubtion after replacing the missing values with mean. \n",
    "\n",
    "train.age.plot.hist(alpha=0.5)\n",
    "raw_titanic.age.plot.hist(alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables of sex in train dataset. \n",
    "\n",
    "sex_dummy = pd.get_dummies(train.sex)\n",
    "train = pd.concat([train, sex_dummy], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fare, pclass, age, and male are the X in model 3. \n",
    "\n",
    "X_train_model3 = train[['fare', 'pclass', 'age', 'male']]\n",
    "y_train_model3 = train[['survived']]\n",
    "\n",
    "X_train_model3.shape, y_train_model3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the logistic regression object\n",
    "\n",
    "logit3 = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "logit3.fit(X_train_model3, y_train_model3)\n",
    "\n",
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit3.coef_)\n",
    "print('Intercept: \\n', logit3.intercept_)\n",
    "\n",
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model3 = logit3.predict(X_train_model3)\n",
    "y_pred_model3\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model3 = logit3.predict_proba(X_train_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy\n",
    "\n",
    "print('Accuracy: {: .2f}'.format(logit3.score(X_train_model3, y_train_model3)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_train_model3, y_pred_model3))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_train_model3, y_pred_model3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. Age columns has 177 null values, about ~20% of all data. \n",
    "2. Most frequence age is 24. \n",
    "3. The mean age is 29.7.\n",
    "4. The median age is 28.0.\n",
    "5. Among whom are missing the age values, 133 are alone, and 44 had accompaniers. \n",
    "\n",
    "**Choice**\n",
    "1. I am gonna use mean as the alternative strategy. Let's see how it affect the performance. \n",
    "\n",
    "**Results**\n",
    "1. The accuracy is increased slightly from 0.79 to 0.80. \n",
    "2. Since the coefficient of age is small (0.027), it doesn't weigh that much in the model, which may explain the reason for such small change in accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2: How do different strategies for encoding sex affect model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire titianic dataset. \n",
    "\n",
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare titianic dataset\n",
    "\n",
    "train, validate, test = prepare.prep_titanic(titanic)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for column sex\n",
    "\n",
    "sex_dummy = pd.get_dummies(train.sex)\n",
    "train = pd.concat([train, sex_dummy], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = ['fare', 'pclass', 'age', 'female']\n",
    "# y = 'survived'\n",
    "\n",
    "X_train_model3 = train[['fare', 'pclass', 'age', 'female']]\n",
    "y_train_model3 = train[['survived']]\n",
    "\n",
    "X_train_model3.shape, y_train_model3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the logistic regression object\n",
    "\n",
    "logit3 = LogisticRegression(C=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "\n",
    "logit3.fit(X_train_model3, y_train_model3)\n",
    "\n",
    "# Print the coefficients and intercept of the model\n",
    "\n",
    "print('Coefficient: \\n', logit3.coef_)\n",
    "print('Intercept: \\n', logit3.intercept_)\n",
    "\n",
    "# Estimate whether or not a passenger would survive, using the training data\n",
    "\n",
    "y_pred_model3 = logit3.predict(X_train_model3)\n",
    "y_pred_model3\n",
    "\n",
    "# Estimate the probablity of a passenger surviving, using the training data\n",
    "y_pred_proba_model3 = logit3.predict_proba(X_train_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy\n",
    "\n",
    "print('Accuracy: {: .2f}'.format(logit3.score(X_train_model3, y_train_model3)))\n",
    "\n",
    "# Create a confusion matrix\n",
    "\n",
    "print('Confusion matrix: \\n', confusion_matrix(y_train_model3, y_pred_model3))\n",
    "\n",
    "# Compute Precision, Recall, F1-score, and Support\n",
    "\n",
    "print(classification_report(y_train_model3, y_pred_model3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. Sex columns has zero null values.\n",
    "2. Sex columns contain 577 males and 312 females.\n",
    "3. In the model 3, the male is 1 and the female is 0.\n",
    "\n",
    "**Alternative stragety for encoding sex**\n",
    "1. The male is 0 and the female is 1. \n",
    "2. My hypothesis is there is no change in the model performance. \n",
    "\n",
    "**Results:**\n",
    "Such encoding doesn't change performance of the model 3. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 3: `scikit-learn`'s `LogisticRegression` classifier is actually applying a regularization penalty to the coefficients by default. \n",
    "\n",
    "* This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. \n",
    "* This value can be modified with the `C` hyperparameter.\n",
    "* Small values of `C` correspond to a larger penalty, and large values of `C` correspond to a smaller penalty.\n",
    "\n",
    "### Try out the following values for `C` and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected. \n",
    "* C = 0.01, 0.1, 1, 10, 100, 1000\n",
    "* Use model 3:\n",
    " - X: fare, pclass, age, male\n",
    " - y: survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load titanic dataset\n",
    "\n",
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the titanic dataset\n",
    "\n",
    "train, validate, test = prepare.prep_titanic(titanic)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variable for column 'sex'\n",
    "\n",
    "sex_dummy = pd.get_dummies(train.sex)\n",
    "train = pd.concat([train, sex_dummy], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[['fare', 'pclass', 'age', 'male']]\n",
    "y_train = train[['survived']]\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that return coefficients given the C value. \n",
    "\n",
    "def logit_model_coefficient(c_value, X, y):\n",
    "    logit = LogisticRegression(C=c_value)\n",
    "    logit.fit(X, y)\n",
    "    coefficient = logit.coef_\n",
    "    return pd.DataFrame(coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcualte the coefficient according to a list of C values\n",
    "\n",
    "list_C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "df = pd.DataFrame()\n",
    "for i in list_C:\n",
    "    df = pd.concat([df, logit_model_coefficient(i, X_train, y_train)])\n",
    "df.index = list_C\n",
    "df.columns = ['fare', 'pclass', 'age', 'male']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "x = [math.log10(i) for i in df.index]\n",
    "y = df.male\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logit_model_accuracy(c_value, X, y):\n",
    "    logit = LogisticRegression(C=c_value)\n",
    "    logit.fit(X, y)\n",
    "    accuracy = logit.score(X, y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model_accuracy(1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_C = [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "\n",
    "accuracy_list = [logit_model_accuracy(i, X_train, y_train) for i in list_C]\n",
    "df = pd.DataFrame(accuracy_list)\n",
    "df.columns = ['Accuracy']\n",
    "df.index = list_C\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [math.log10(i) for i in df.index]\n",
    "y = df.Accuracy\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Exercises\n",
    "\n",
    "### In this exercise, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.\n",
    "* Continue working in your model file. Add, commit, and push your changes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire titanic dataset\n",
    "\n",
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>25.4667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sibsp  parch     fare  alone  sex_male  \\\n",
       "313         0       3  28.0      0      0   7.8958      1         1   \n",
       "636         0       3  32.0      0      0   7.9250      1         1   \n",
       "222         0       3  51.0      0      0   8.0500      1         1   \n",
       "485         0       3  24.0      3      1  25.4667      0         0   \n",
       "553         1       3  22.0      0      0   7.2250      1         1   \n",
       "\n",
       "     embarked_Q  embarked_S  \n",
       "313           0           1  \n",
       "636           0           1  \n",
       "222           0           1  \n",
       "485           0           1  \n",
       "553           0           0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare titanic dataset\n",
    "\n",
    "train, validate, test = prepare.prep_titanic(titanic)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 497 entries, 583 to 553\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   survived    497 non-null    int64  \n",
      " 1   pclass      497 non-null    int64  \n",
      " 2   age         497 non-null    float64\n",
      " 3   sibsp       497 non-null    int64  \n",
      " 4   parch       497 non-null    int64  \n",
      " 5   fare        497 non-null    float64\n",
      " 6   alone       497 non-null    int64  \n",
      " 7   sex_male    497 non-null    uint8  \n",
      " 8   embarked_Q  497 non-null    uint8  \n",
      " 9   embarked_S  497 non-null    uint8  \n",
      "dtypes: float64(2), int64(5), uint8(3)\n",
      "memory usage: 32.5 KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((497, 10), (214, 10), (178, 10))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "### 2. Evaluate your in-sample results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train and y_train\n",
    "\n",
    "X_train_BL = train[['fare', 'pclass']]\n",
    "y_train_BL = train['survived']\n",
    "\n",
    "X_train_1 = train[['fare', 'pclass', 'age']]\n",
    "y_train_1 = train['survived']\n",
    "\n",
    "X_train_2 = train[['fare', 'pclass', 'age', 'sex_male']]\n",
    "y_train_2 = train['survived']\n",
    "\n",
    "X_train_3 = train[['pclass', 'sex_male']]\n",
    "y_train_3 = train['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((497, 2), (497, 3))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_BL.shape, X_train_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [['baseline', X_train_BL, y_train_BL], \n",
    "          ['model1', X_train_1, y_train_1], \n",
    "          ['model2', X_train_2, y_train_2],\n",
    "          ['model3', X_train_3, y_train_3]\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'baseline'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model2</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model3</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>model1</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      model  accuracy\n",
       "0    model2      0.82\n",
       "1    model3      0.79\n",
       "2  baseline      0.69\n",
       "3    model1      0.69"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalute the models using model score\n",
    "\n",
    "output = []\n",
    "\n",
    "def tree_accuracy(X, y):\n",
    "    clf.fit(X, y)\n",
    "    accuracy = clf.score(X, y)\n",
    "    return accuracy\n",
    "\n",
    "for model in models:\n",
    "    output.append({'model': model[0],\n",
    "                   \"accuracy\": tree_accuracy(model[1], model[2]).round(2)\n",
    "                  })\n",
    "\n",
    "matrics = pd.DataFrame(output)\n",
    "matrics.sort_values(by='accuracy', ascending=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>baseline</th>\n",
       "      <th>model1</th>\n",
       "      <th>model2</th>\n",
       "      <th>model3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  baseline  model1  model2  model3\n",
       "0       0         0       0       0       0\n",
       "1       1         1       1       1       1\n",
       "2       0         0       0       0       0\n",
       "3       1         1       1       1       1\n",
       "4       1         1       1       1       1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tree_y_pred(X, y):\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    return y_pred\n",
    "\n",
    "# tree_y_pred(X_train_1, y_train_1)\n",
    "\n",
    "output = pd.DataFrame(train['survived']).reset_index(drop=True)\n",
    "output.rename(columns = {'survived':'actual'}, inplace=True)\n",
    "\n",
    "for model in models:\n",
    "    output[model[0]] = tree_y_pred(model[1], model[2])\n",
    "\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix of baseline is:\n",
      "           victim  survived\n",
      "victim       279        28\n",
      "survived     126        64\n",
      "\n",
      "The confusion matrix of model1 is:\n",
      "           victim  survived\n",
      "victim       279        28\n",
      "survived     126        64\n",
      "\n",
      "The confusion matrix of model2 is:\n",
      "           victim  survived\n",
      "victim       279        28\n",
      "survived      62       128\n",
      "\n",
      "The confusion matrix of model3 is:\n",
      "           victim  survived\n",
      "victim       303         4\n",
      "survived     100        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels = ['victim', 'survived']\n",
    "\n",
    "for model in models:\n",
    "    df = pd.crosstab(output.actual, output[model[0]])\n",
    "    df.index = df.columns = labels\n",
    "    print(f'The confusion matrix of {model[0]} is:\\n {df}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of Baseline Model:\n",
      " [[279  28]\n",
      " [126  64]]\n",
      "Confusion matrix of Model 1:\n",
      " [[279  28]\n",
      " [126  64]]\n",
      "Confusion matrix of Model 2:\n",
      " [[279  28]\n",
      " [ 62 128]]\n",
      "Confusion matrix of Model 3:\n",
      " [[303   4]\n",
      " [100  90]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models by confusion matrix\n",
    "\n",
    "def tree_matrix(X, y):\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    matrix = confusion_matrix(y, y_pred)\n",
    "    return matrix\n",
    "\n",
    "print('Confusion matrix of Baseline Model:\\n', tree_matrix(X_train_BL, y_train_BL))\n",
    "print('Confusion matrix of Model 1:\\n', tree_matrix(X_train_1, y_train_1))\n",
    "print('Confusion matrix of Model 2:\\n', tree_matrix(X_train_2, y_train_2))\n",
    "print('Confusion matrix of Model 3:\\n', tree_matrix(X_train_3, y_train_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report of Baseline Model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.78       307\n",
      "           1       0.70      0.34      0.45       190\n",
      "\n",
      "    accuracy                           0.69       497\n",
      "   macro avg       0.69      0.62      0.62       497\n",
      "weighted avg       0.69      0.69      0.66       497\n",
      "\n",
      "Classification report of Model 1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.91      0.78       307\n",
      "           1       0.70      0.34      0.45       190\n",
      "\n",
      "    accuracy                           0.69       497\n",
      "   macro avg       0.69      0.62      0.62       497\n",
      "weighted avg       0.69      0.69      0.66       497\n",
      "\n",
      "Classification report of Model 2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86       307\n",
      "           1       0.82      0.67      0.74       190\n",
      "\n",
      "    accuracy                           0.82       497\n",
      "   macro avg       0.82      0.79      0.80       497\n",
      "weighted avg       0.82      0.82      0.81       497\n",
      "\n",
      "Classification report of Model 3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.85       307\n",
      "           1       0.96      0.47      0.63       190\n",
      "\n",
      "    accuracy                           0.79       497\n",
      "   macro avg       0.85      0.73      0.74       497\n",
      "weighted avg       0.83      0.79      0.77       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models by classification report\n",
    "\n",
    "def tree_report(X, y):\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    report = classification_report(y, y_pred)\n",
    "    return report\n",
    "\n",
    "print('Classification report of Baseline Model:\\n', tree_report(X_train_BL, y_train_BL))\n",
    "print('Classification report of Model 1:\\n', tree_report(X_train_1, y_train_1))\n",
    "print('Classification report of Model 2:\\n', tree_report(X_train_2, y_train_2))\n",
    "print('Classification report of Model 3:\\n', tree_report(X_train_3, y_train_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "* Accuracy\n",
    "* TPR = Recall(1)\n",
    "* TNR = Recall(0)\n",
    "* FPR = 1 - Recall(0)\n",
    "* FNR = 1 - Recall(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Baseline Model:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.688889  0.908795  0.783708    307.0  0.091205  0.690141\n",
      "1   0.695652  0.336842  0.453901    190.0  0.663158  0.690141 \n",
      "\n",
      "Performance of Model 1:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.688889  0.908795  0.783708    307.0  0.091205  0.690141\n",
      "1   0.695652  0.336842  0.453901    190.0  0.663158  0.690141 \n",
      "\n",
      "Performance of Model 2:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.818182  0.908795  0.861111    307.0  0.091205  0.818913\n",
      "1   0.820513  0.673684  0.739884    190.0  0.326316  0.818913 \n",
      "\n",
      "Performance of Model 3:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.751861  0.986971  0.853521    307.0  0.013029  0.790744\n",
      "1   0.957447  0.473684  0.633803    190.0  0.526316  0.790744 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tree_report_dataframe(X, y):\n",
    "    clf.fit(X, y)\n",
    "    y_pred = clf.predict(X)\n",
    "    accuracy = clf.score(X,y)\n",
    "    report = classification_report(y, y_pred, output_dict=True)\n",
    "    report = pd.DataFrame(report)\n",
    "    report.drop(columns=['macro avg', 'weighted avg', 'accuracy'], inplace=True)\n",
    "    report = report.T\n",
    "    report['FPR/FNR'] = 1 - report.recall\n",
    "    report['accuracy'] = accuracy\n",
    "    report.rename(columns={'recall':'TNR/TPR'}, inplace=True)\n",
    "    return report\n",
    "\n",
    "print('Performance of Baseline Model:\\n', tree_report_dataframe(X_train_BL, y_train_BL), '\\n')\n",
    "print('Performance of Model 1:\\n', tree_report_dataframe(X_train_1, y_train_1), '\\n')\n",
    "print('Performance of Model 2:\\n', tree_report_dataframe(X_train_2, y_train_2), '\\n')\n",
    "print('Performance of Model 3:\\n', tree_report_dataframe(X_train_3, y_train_3), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps 2-4 using a different max_depth value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Decision Tree Object with different max_depth value\n",
    "\n",
    "clf5 = DecisionTreeClassifier(max_depth=5, random_state=123)\n",
    "clf10 = DecisionTreeClassifier(max_depth=10, random_state=123)\n",
    "clf20 = DecisionTreeClassifier(max_depth=20, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Baseline Model:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.709756  0.947883  0.811715    307.0  0.052117   0.72837\n",
      "1   0.816092  0.373684  0.512635    190.0  0.626316   0.72837 \n",
      "\n",
      "Performance of Model 1:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.722922  0.934853  0.815341    307.0  0.065147  0.738431\n",
      "1   0.800000  0.421053  0.551724    190.0  0.578947  0.738431 \n",
      "\n",
      "Performance of Model 2:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.871473  0.905537  0.888179    307.0  0.094463  0.859155\n",
      "1   0.837079  0.784211  0.809783    190.0  0.215789  0.859155 \n",
      "\n",
      "Performance of Model 3:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.751861  0.986971  0.853521    307.0  0.013029  0.790744\n",
      "1   0.957447  0.473684  0.633803    190.0  0.526316  0.790744 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tree_report_dataframe_max5(X, y):\n",
    "    clf5.fit(X, y)\n",
    "    y_pred = clf5.predict(X)\n",
    "    accuracy = clf5.score(X,y)\n",
    "    report = classification_report(y, y_pred, output_dict=True)\n",
    "    report = pd.DataFrame(report)\n",
    "    report.drop(columns=['macro avg', 'weighted avg', 'accuracy'], inplace=True)\n",
    "    report = report.T\n",
    "    report['FPR/FNR'] = 1 - report.recall\n",
    "    report['accuracy'] = accuracy\n",
    "    report.rename(columns={'recall':'TNR/TPR'}, inplace=True)\n",
    "    return report\n",
    "\n",
    "print('Performance of Baseline Model:\\n', tree_report_dataframe_max5(X_train_BL, y_train_BL), '\\n')\n",
    "print('Performance of Model 1:\\n', tree_report_dataframe_max5(X_train_1, y_train_1), '\\n')\n",
    "print('Performance of Model 2:\\n', tree_report_dataframe_max5(X_train_2, y_train_2), '\\n')\n",
    "print('Performance of Model 3:\\n', tree_report_dataframe_max5(X_train_3, y_train_3), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Baseline Model:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.830619  0.830619  0.830619    307.0  0.169381  0.790744\n",
      "1   0.726316  0.726316  0.726316    190.0  0.273684  0.790744 \n",
      "\n",
      "Performance of Model 1:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.935361  0.801303  0.863158    307.0  0.198697  0.843058\n",
      "1   0.739316  0.910526  0.816038    190.0  0.089474  0.843058 \n",
      "\n",
      "Performance of Model 2:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.923313  0.980456  0.951027    307.0  0.019544  0.937626\n",
      "1   0.964912  0.868421  0.914127    190.0  0.131579  0.937626 \n",
      "\n",
      "Performance of Model 3:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.751861  0.986971  0.853521    307.0  0.013029  0.790744\n",
      "1   0.957447  0.473684  0.633803    190.0  0.526316  0.790744 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tree_report_dataframe_max10(X, y):\n",
    "    clf10.fit(X, y)\n",
    "    y_pred = clf10.predict(X)\n",
    "    accuracy = clf10.score(X,y)\n",
    "    report = classification_report(y, y_pred, output_dict=True)\n",
    "    report = pd.DataFrame(report)\n",
    "    report.drop(columns=['macro avg', 'weighted avg', 'accuracy'], inplace=True)\n",
    "    report = report.T\n",
    "    report['FPR/FNR'] = 1 - report.recall\n",
    "    report['accuracy'] = accuracy\n",
    "    report.rename(columns={'recall':'TNR/TPR'}, inplace=True)\n",
    "    return report\n",
    "\n",
    "print('Performance of Baseline Model:\\n', tree_report_dataframe_max10(X_train_BL, y_train_BL), '\\n')\n",
    "print('Performance of Model 1:\\n', tree_report_dataframe_max10(X_train_1, y_train_1), '\\n')\n",
    "print('Performance of Model 2:\\n', tree_report_dataframe_max10(X_train_2, y_train_2), '\\n')\n",
    "print('Performance of Model 3:\\n', tree_report_dataframe_max10(X_train_3, y_train_3), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of Baseline Model:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.804813  0.980456  0.883994    307.0  0.019544  0.841046\n",
      "1   0.951220  0.615789  0.747604    190.0  0.384211  0.841046 \n",
      "\n",
      "Performance of Model 1:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.964516  0.973941  0.969206    307.0  0.026059  0.961771\n",
      "1   0.957219  0.942105  0.949602    190.0  0.057895  0.961771 \n",
      "\n",
      "Performance of Model 2:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.977707  1.000000  0.988728    307.0  0.000000  0.985915\n",
      "1   1.000000  0.963158  0.981233    190.0  0.036842  0.985915 \n",
      "\n",
      "Performance of Model 3:\n",
      "    precision   TNR/TPR  f1-score  support   FPR/FNR  accuracy\n",
      "0   0.751861  0.986971  0.853521    307.0  0.013029  0.790744\n",
      "1   0.957447  0.473684  0.633803    190.0  0.526316  0.790744 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def tree_report_dataframe_max20(X, y):\n",
    "    clf20.fit(X, y)\n",
    "    y_pred = clf20.predict(X)\n",
    "    accuracy = clf20.score(X,y)\n",
    "    report = classification_report(y, y_pred, output_dict=True)\n",
    "    report = pd.DataFrame(report)\n",
    "    report.drop(columns=['macro avg', 'weighted avg', 'accuracy'], inplace=True)\n",
    "    report = report.T\n",
    "    report['FPR/FNR'] = 1 - report.recall\n",
    "    report['accuracy'] = accuracy\n",
    "    report.rename(columns={'recall':'TNR/TPR'}, inplace=True)\n",
    "    return report\n",
    "\n",
    "print('Performance of Baseline Model:\\n', tree_report_dataframe_max20(X_train_BL, y_train_BL), '\\n')\n",
    "print('Performance of Model 1:\\n', tree_report_dataframe_max20(X_train_1, y_train_1), '\\n')\n",
    "print('Performance of Model 2:\\n', tree_report_dataframe_max20(X_train_2, y_train_2), '\\n')\n",
    "print('Performance of Model 3:\\n', tree_report_dataframe_max20(X_train_3, y_train_3), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Which performs better on your in-sample data?\n",
    "* Model 2 with max_indepth = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The baseline accuracy is 0.618\n",
    "2. My baseline model is X = ['fare', 'pclass'], y = 'survived'\n",
    "3. Model 1: X = ['fare', 'pclass', 'age']\n",
    "4. Model 2: X = ['fare', 'pclass', 'age', 'male']\n",
    "5. Model 3: X = ['pclass', 'male']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Exercises\n",
    "* Continue working in your model file. Be sure to add, commit, and push your changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 20.\n",
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire titanic dataset\n",
    "\n",
    "titanic = acquire.get_titanic_data()\n",
    "titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embarked_Q</th>\n",
       "      <th>embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>134.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.2917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>146.5208</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass   age  sibsp  parch      fare  alone  sex_male  \\\n",
       "583         0       1  36.0      0      0   40.1250      1         1   \n",
       "337         1       1  41.0      0      0  134.5000      1         0   \n",
       "50          0       3   7.0      4      1   39.6875      0         1   \n",
       "218         1       1  32.0      0      0   76.2917      1         0   \n",
       "31          1       1  24.0      1      0  146.5208      0         0   \n",
       "\n",
       "     embarked_Q  embarked_S  \n",
       "583           0           0  \n",
       "337           0           0  \n",
       "50            0           1  \n",
       "218           0           0  \n",
       "31            0           0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare titanic dataset\n",
    "\n",
    "train, validate, test = prepare.prep_titanic(titanic)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((497, 4), (214, 4), (178, 4))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train and y_train\n",
    "\n",
    "X_train = train[['fare', 'pclass', 'age', 'sex_male']]\n",
    "y_train = train['survived']\n",
    "\n",
    "X_validate = validate[['fare', 'pclass', 'age', 'sex_male']]\n",
    "y_validate = validate['survived']\n",
    "\n",
    "X_test = test[['fare', 'pclass', 'age', 'sex_male']]\n",
    "y_test = test['survived']\n",
    "\n",
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat the Random Forest Object\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, \n",
    "                            max_depth=20, \n",
    "                            min_samples_split=2, \n",
    "                            min_samples_leaf=1, \n",
    "                            random_state=433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=20, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=433,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit to the training dataset.\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the model score:\n",
    "\n",
    "accuracy_rf = rf.score(X_train, y_train)\n",
    "accuracy_rf.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the predicted y\n",
    "\n",
    "y_pred_rf = rf.predict(X_train)\n",
    "y_pred_rf[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[305,   2],\n",
       "       [  5, 185]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the confusion matrix\n",
    "\n",
    "confusion_matrix(y_train, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       307\n",
      "           1       0.99      0.97      0.98       190\n",
      "\n",
      "    accuracy                           0.99       497\n",
      "   macro avg       0.99      0.98      0.99       497\n",
      "weighted avg       0.99      0.99      0.99       497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the classification report\n",
    "\n",
    "print(classification_report(y_train, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>TNR/TPR</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>FPR/FNR</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.989</td>\n",
       "      <td>307.0</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.989</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.981</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  TNR/TPR  f1-score  support  FPR/FNR  accuracy\n",
       "0      0.984    0.993     0.989    307.0    0.007     0.986\n",
       "1      0.989    0.974     0.981    190.0    0.026     0.986"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics(rf, X_train, y_train).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf to 5 and decreasing your max_depth to 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new Random Forest Object\n",
    "\n",
    "rf1 = RandomForestClassifier(n_estimators=100, \n",
    "                            max_depth=3, \n",
    "                            min_samples_split=2, \n",
    "                            min_samples_leaf=5, \n",
    "                            random_state=433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>TNR/TPR</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>FPR/FNR</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.811</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.874</td>\n",
       "      <td>307.0</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.884</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.744</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.358</td>\n",
       "      <td>0.831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  TNR/TPR  f1-score  support  FPR/FNR  accuracy\n",
       "0      0.811    0.948     0.874    307.0    0.052     0.831\n",
       "1      0.884    0.642     0.744    190.0    0.358     0.831"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the new algorithms\n",
    "\n",
    "model_metrics(rf1, X_train, y_train).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "1. The accuracy drop from 0.99 to 0.83\n",
    "2. The rf performas better on the in-sample data, due to high max_depth and low min_sample_leaf. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: How about out-of-sample data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>TNR/TPR</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>FPR/FNR</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.992</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.992</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.988</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  TNR/TPR  f1-score  support  FPR/FNR  accuracy\n",
       "0      0.992    0.992     0.992    132.0    0.008     0.991\n",
       "1      0.988    0.988     0.988     82.0    0.012     0.991"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics(rf, X_validate, y_validate).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>TNR/TPR</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>FPR/FNR</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.991</td>\n",
       "      <td>0.991</td>\n",
       "      <td>0.991</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.985</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  TNR/TPR  f1-score  support  FPR/FNR  accuracy\n",
       "0      0.991    0.991     0.991    110.0    0.009     0.989\n",
       "1      0.985    0.985     0.985     68.0    0.015     0.989"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics(rf, X_test, y_test).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>TNR/TPR</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>FPR/FNR</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.962</td>\n",
       "      <td>0.876</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.911</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.739</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  TNR/TPR  f1-score  support  FPR/FNR  accuracy\n",
       "0      0.804    0.962     0.876    132.0    0.038     0.832\n",
       "1      0.911    0.622     0.739     82.0    0.378     0.832"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics(rf1, X_validate, y_validate).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>TNR/TPR</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>FPR/FNR</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.879</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.866</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.791</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision  TNR/TPR  f1-score  support  FPR/FNR  accuracy\n",
       "0      0.879    0.855     0.866    110.0    0.145     0.837\n",
       "1      0.775    0.809     0.791     68.0    0.191     0.837"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_metrics(rf1, X_test, y_test).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "1. The dataset I am gonna use is titanic\n",
    "    * baseline accuracy: \n",
    "    * baseline model: X = ['fare','pclass']\n",
    "    * best performance model so far: X = ['fare', 'pclass', 'age', 'sex_male']\n",
    "2. rf: [100, 20, 2, 1, 433]\n",
    "    * accuracy is 0.99, much higher than the baseline and lr and clf.\n",
    "    * hightly possiblely overfit\n",
    "3. rf: [100, 3, 2, 5, 433]\n",
    "4. I am surprise to find no overfitting issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
